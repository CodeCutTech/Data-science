{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep Dive into DuckDB for Data Scientists\n",
    "\n",
    "## Zero Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create sample data\n",
    "sales = pd.DataFrame(\n",
    "    {\n",
    "        \"product\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\"] * 2,\n",
    "        \"region\": [\"North\", \"South\"] * 6,\n",
    "        \"amount\": [100, 150, 200, 120, 180, 220, 110, 160, 210, 130, 170, 230],\n",
    "        \"date\": pd.date_range(\"2024-01-01\", periods=12),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/postgres\")\n",
    "\n",
    "# Write the DataFrame to a PostgreSQL table\n",
    "sales.to_sql(\"sales\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Execute SQL query against the PostgreSQL database\n",
    "with engine.connect() as conn:\n",
    "    result = pd.read_sql(\"SELECT product, region, amount FROM sales\", conn)\n",
    "\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Direct SQL operations on DataFrame - no server needed\n",
    "result = duckdb.sql(\"SELECT product, region, amount FROM sales\").df()\n",
    "\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Seamlessly with pandas and Polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "pd_df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "\n",
    "pl_df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "\n",
    "duckdb.sql(\"SELECT * FROM pd_df\").df()\n",
    "duckdb.sql(\"SELECT * FROM pl_df\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Use pandas for data cleaning and feature engineering\n",
    "sales[\"month\"] = sales[\"date\"].dt.month\n",
    "sales[\"is_high_value\"] = sales[\"amount\"] > 150\n",
    "print(\"Sales after feature engineering:\")\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DuckDB for complex aggregations\n",
    "analysis = duckdb.sql(\"\"\"\n",
    "    SELECT \n",
    "        product,\n",
    "        region,\n",
    "        COUNT(*) as total_sales,\n",
    "        AVG(amount) as avg_amount,\n",
    "        SUM(CASE WHEN is_high_value THEN 1 ELSE 0 END) as high_value_sales\n",
    "    FROM sales\n",
    "    GROUP BY product, region\n",
    "    ORDER BY avg_amount DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Sales analysis by product and region:\")\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas for visualization\n",
    "from utils import apply_codecut_style\n",
    "\n",
    "# Create a simple bar plot\n",
    "ax = analysis.pivot_table(\n",
    "    values=\"avg_amount\", index=\"product\", columns=\"region\"\n",
    ").plot(kind=\"bar\", color=[\"#72BEFA\", \"#E583B6\"])\n",
    "\n",
    "ax.set_title(\"Average Sales Amount by Product and Region\")\n",
    "ax.set_xlabel(\"Product\")\n",
    "ax.set_ylabel(\"Average Amount\")\n",
    "apply_codecut_style(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample datasets\n",
    "n_rows = 1_000_000\n",
    "\n",
    "# Customers dataset\n",
    "customers = pd.DataFrame({\n",
    "    \"customer_id\": range(n_rows),\n",
    "    \"name\": [f\"Customer_{i}\" for i in range(n_rows)],\n",
    "    \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], n_rows),\n",
    "    \"segment\": np.random.choice([\"A\", \"B\", \"C\"], n_rows)\n",
    "})\n",
    "\n",
    "# Save to Parquet\n",
    "customers.to_csv(\"data/customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"data/customers.csv\")\n",
    "\n",
    "# Filter the data\n",
    "result = df[df[\"region\"] == \"North\"]\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query a CSV file directly\n",
    "result = duckdb.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM 'data/customers.csv'\n",
    "    WHERE region = 'North'\n",
    "\"\"\").df()\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas aggregation\n",
    "start_time = time.time()\n",
    "pandas_agg = customers.groupby([\"region\", \"segment\"]).size().reset_index(name=\"count\")\n",
    "pandas_time = time.time() - start_time\n",
    "\n",
    "# DuckDB aggregation\n",
    "start_time = time.time()\n",
    "duckdb_agg = duckdb.sql(\"\"\"\n",
    "    SELECT region, segment, COUNT(*) as count FROM customers GROUP BY region, segment\n",
    "\"\"\").df()\n",
    "duckdb_time = time.time() - start_time\n",
    "\n",
    "# Print the results\n",
    "print(f\"Pandas aggregation time: {pandas_time:.2f} seconds\")\n",
    "print(f\"DuckDB aggregation time: {duckdb_time:.2f} seconds\")\n",
    "print(f\"Speedup: {pandas_time/duckdb_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined File Reading\n",
    "\n",
    "### Automatic Parsing of CSV Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example CSV content with a custom delimiter\n",
    "csv_content = \"\"\"FlightDate|UniqueCarrier|OriginCityName|DestCityName\n",
    "1988-01-01|AA|New York, NY|Los Angeles, CA\n",
    "1988-01-02|AA|New York, NY|Los Angeles, CA\n",
    "1988-01-03|AA|New York, NY|Los Angeles, CA\n",
    "\"\"\"\n",
    "\n",
    "## Writing the CSV content to a file\n",
    "with open(\"data/flight_data.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "## Reading the CSV file with pandas without specifying the delimiter\n",
    "df = pd.read_csv(\"data/flight_data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "## Use DuckDB to automatically detect and read the CSV structure\n",
    "result = duckdb.query(\"SELECT * FROM read_csv('data/flight_data.csv')\").to_df()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Flattening of Nested Parquet Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a nested dataset and save it as a Parquet file\n",
    "data = {\n",
    "    \"id\": [1, 2],\n",
    "    \"details\": [{\"name\": \"Alice\", \"age\": 25}, {\"name\": \"Bob\", \"age\": 30}],\n",
    "}\n",
    "\n",
    "## Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save as a nested Parquet file\n",
    "df.to_parquet(\"data/customers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the DataFrame from Parquet file\n",
    "df = pd.read_parquet(\"data/customers.parquet\")\n",
    "\n",
    "# Create a new DataFrame with the flattened structure\n",
    "flat_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": df[\"id\"],\n",
    "        \"name\": [detail[\"name\"] for detail in df[\"details\"]],\n",
    "        \"age\": [detail[\"age\"] for detail in df[\"details\"]],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(flat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "## Query the nested Parquet file directly\n",
    "query_result = duckdb.query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        id,\n",
    "        details.name AS name,\n",
    "        details.age AS age\n",
    "    FROM read_parquet('data/customers.parquet')\n",
    "\"\"\"\n",
    ").to_df()\n",
    "\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Flattening of Nested JSON Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample JSON data\n",
    "n_rows = 5\n",
    "\n",
    "# Generate nested JSON data\n",
    "data = []\n",
    "for i in range(n_rows):\n",
    "    record = {\n",
    "        \"user_id\": i,\n",
    "        \"profile\": {\"name\": f\"User_{i}\", \"active\": np.random.choice([True, False])},\n",
    "    }\n",
    "    data.append(record)\n",
    "\n",
    "# Save as JSON file\n",
    "with open(\"data/users.json\", \"w\") as f:\n",
    "    json.dump(data, f, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "with open(\"data/users.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON with pandas\n",
    "import pandas as pd\n",
    "\n",
    "df_normalized = pd.json_normalize(\n",
    "    data,\n",
    "    meta=[\"user_id\", [\"profile\", \"name\"], [\"profile\", \"active\"]],\n",
    ")\n",
    "\n",
    "print(\"Normalized data:\")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query JSON directly\n",
    "result = duckdb.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        profile.name,\n",
    "        profile.active\n",
    "    FROM read_json('data/users.json')\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "print(\"JSON query results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Multiple Files\n",
    "\n",
    "### Reading Multiple Files from a Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create example dataframe for first file\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n",
    "        \"Product\": [\"Laptop\", \"Phone\", \"Tablet\"],\n",
    "        \"Sales\": [1200, 800, 600],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create example dataframe for second file\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": [\"2023-02-01\", \"2023-02-02\", \"2023-02-03\"],\n",
    "        \"Product\": [\"Laptop\", \"Monitor\", \"Mouse\"],\n",
    "        \"Sales\": [1500, 400, 50],\n",
    "    }\n",
    ")\n",
    "\n",
    "Path(\"data/sales\").mkdir(parents=True, exist_ok=True)\n",
    "df1.to_csv(\"data/sales/jan.csv\", index=False)\n",
    "df2.to_csv(\"data/sales/feb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Read each file separately\n",
    "df1 = pd.read_csv(\"data/sales/jan.csv\")\n",
    "df2 = pd.read_csv(\"data/sales/feb.csv\")\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "df = pd.concat([df1, df2])\n",
    "print(df.sort_values(by=\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "## Read and analyze all CSV files at once\n",
    "result = duckdb.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM 'data/sales/*.csv'\n",
    "\"\"\"\n",
    ").df()\n",
    "print(result.sort_values(by=\"Date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read From Multiple Sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample data in different formats\n",
    "n_rows = 5\n",
    "\n",
    "# 1. Create a CSV file with customer data\n",
    "customers = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": range(n_rows),\n",
    "        \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], n_rows),\n",
    "    }\n",
    ")\n",
    "customers.to_csv(\"data/customers.csv\", index=False)\n",
    "\n",
    "# 2. Create a Parquet file with order data\n",
    "orders = pd.DataFrame(\n",
    "    {\n",
    "        \"order_id\": range(n_rows),\n",
    "        \"customer_id\": np.random.randint(0, n_rows, n_rows),\n",
    "        \"amount\": np.random.normal(100, 30, n_rows),\n",
    "    }\n",
    ")\n",
    "orders.to_parquet(\"data/orders.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query combining data from CSV and Parquet\n",
    "result = duckdb.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        c.region,\n",
    "        COUNT(DISTINCT c.customer_id) as unique_customers,\n",
    "        AVG(o.amount) as avg_order_amount,\n",
    "        SUM(o.amount) as total_revenue\n",
    "    FROM 'data/customers.csv' c\n",
    "    JOIN 'data/orders.parquet' o\n",
    "        ON c.customer_id = o.customer_id\n",
    "    GROUP BY c.region\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "print(\"Sales Analysis by Region:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterized Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Create a new database file\n",
    "conn = duckdb.connect(\"data/bank.db\")\n",
    "\n",
    "# Create accounts table\n",
    "conn.sql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE accounts (account_id INTEGER, name VARCHAR, balance DECIMAL(10,2))\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Insert sample accounts\n",
    "conn.sql(\n",
    "    \"\"\"\n",
    "    INSERT INTO accounts VALUES(1, 'Alice', 1000.00), (2, 'Bob', 500.00), (3, 'Charlie', 750.00)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Open a connection\n",
    "conn = duckdb.connect(\"data/bank.db\")\n",
    "\n",
    "name_1 = \"A\"\n",
    "balance_1 = 100\n",
    "\n",
    "name_2 = \"C\"\n",
    "balance_2 = 200\n",
    "\n",
    "# Execute a query with parameters\n",
    "result_1 = conn.sql(\n",
    "    f\"SELECT * FROM accounts WHERE starts_with(name, '{name_1}') AND balance > {balance_1}\"\n",
    ").df()\n",
    "\n",
    "result_2 = conn.sql(\n",
    "    f\"SELECT * FROM accounts WHERE starts_with(name, '{name_2}') AND balance > {balance_2}\"\n",
    ").df()\n",
    "\n",
    "print(f\"result_1:\\n{result_1}\")\n",
    "print(f\"result_2:\\n{result_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = conn.execute(\n",
    "    \"SELECT * FROM accounts WHERE starts_with(name, ?) AND balance > ?\",\n",
    "    (name_1, balance_1),\n",
    ").df()\n",
    "\n",
    "result_2 = conn.execute(\n",
    "    \"SELECT * FROM accounts WHERE starts_with(name, ?) AND balance > ?\",\n",
    "    (name_2, balance_2),\n",
    ").df()\n",
    "\n",
    "print(f\"result_1:\\n{result_1}\")\n",
    "print(f\"result_2:\\n{result_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACID Transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Open a connection\n",
    "conn = duckdb.connect(\"data/bank.db\")\n",
    "\n",
    "\n",
    "def transfer_money(from_account, to_account, amount):\n",
    "    # Begin transaction\n",
    "    conn.sql(\"BEGIN TRANSACTION\")\n",
    "\n",
    "    # Check balance\n",
    "    balance = conn.execute(\n",
    "        \"SELECT balance FROM accounts WHERE account_id = ?\", (from_account,)\n",
    "    ).fetchone()[0]\n",
    "\n",
    "    if balance >= amount:\n",
    "        # Deduct money\n",
    "        conn.execute(\n",
    "            \"UPDATE accounts SET balance = balance - ? WHERE account_id = ?\",\n",
    "            (amount, from_account),\n",
    "        )\n",
    "\n",
    "        # Add money\n",
    "        conn.execute(\n",
    "            \"UPDATE accounts SET balance = balance + ? WHERE account_id = ?\",\n",
    "            (amount, to_account),\n",
    "        )\n",
    "\n",
    "        # Commit transaction\n",
    "        conn.sql(\"COMMIT\")\n",
    "    else:\n",
    "        # Rollback transaction\n",
    "        conn.sql(\"ROLLBACK\")\n",
    "        print(f\"Insufficient funds: {balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show initial balances\n",
    "print(\"Initial balances:\")\n",
    "print(conn.sql(\"SELECT * FROM accounts\").df())\n",
    "\n",
    "# Perform a valid transfer\n",
    "print(\"\\nPerforming valid transfer of $200 from Alice to Bob:\")\n",
    "transfer_money(1, 2, 200)\n",
    "\n",
    "# Show balances after valid transfer\n",
    "print(\"\\nBalances after valid transfer:\")\n",
    "print(conn.sql(\"SELECT * FROM accounts\").df())\n",
    "\n",
    "# Attempt an invalid transfer (insufficient funds)\n",
    "print(\"\\nAttempting invalid transfer of $1000 from Bob to Charlie:\")\n",
    "transfer_money(2, 3, 1000)\n",
    "\n",
    "# Show balances after failed transfer (should be unchanged)\n",
    "print(\"\\nBalances after failed transfer (should be unchanged):\")\n",
    "print(conn.sql(\"SELECT * FROM accounts\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Create a connection\n",
    "conn = duckdb.connect(\"data/articles.db\")\n",
    "\n",
    "# Create a table with articles\n",
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE articles (\n",
    "        article_id VARCHAR,\n",
    "        title VARCHAR,\n",
    "        content VARCHAR,\n",
    "        publish_date DATE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample articles\n",
    "conn.sql(\"\"\"\n",
    "    INSERT INTO articles VALUES\n",
    "        ('art1', 'Introduction to DuckDB',\n",
    "         'DuckDB is an embedded analytical database that supports SQL queries on local files.',\n",
    "         '2024-01-15'),\n",
    "        ('art2', 'Working with Large Datasets',\n",
    "         'Learn how to efficiently process large datasets using DuckDB and its powerful features.',\n",
    "         '2024-02-01'),\n",
    "        ('art3', 'SQL Performance Tips',\n",
    "         'Optimize your SQL queries for better performance in analytical workloads.',\n",
    "         '2024-02-15')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    PRAGMA create_fts_index('articles', 'article_id', 'title', 'content')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = conn.sql(\"\"\"\n",
    "    SELECT article_id, title, content, score\n",
    "    FROM (\n",
    "        SELECT *, fts_main_articles.match_bm25(article_id, 'DuckDB', fields := 'title,content') AS score\n",
    "        FROM articles\n",
    "    ) sq\n",
    "    WHERE score IS NOT NULL\n",
    "    ORDER BY score DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Articles about DuckDB:\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/khuyentran/.pyenv/versions/3.11.2/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
